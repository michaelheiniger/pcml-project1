{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "from data_modification import replace_by_mean\n",
    "\n",
    "\"\"\" Load TRAINING data \"\"\"\n",
    "DATA_TRAIN_PATH = '/Users/chiara/Documents/EPFL/Master/Ma1/MachineLearning/project1/data/train.csv'\n",
    "y, raw_tx, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "# Replace -999 by the mean of its respective column\n",
    "processed_tx = replace_by_mean(raw_tx)\n",
    "\n",
    "# Standardize (subtract mean and divive by standard deviation)\n",
    "processed_tx,_,_ = standardize(processed_tx)\n",
    "\n",
    "\"\"\" Load TEST data \"\"\"\n",
    "DATA_TEST_PATH = '/Users/chiara/Documents/EPFL/Master/Ma1/MachineLearning/project1/data/test.csv' # download test data and supply path here \n",
    "_, raw_tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "processed_tx_test = replace_by_mean(raw_tX_test)\n",
    "processed_tx_test,_,_ = standardize(processed_tx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reg_logistic_regression import reg_logistic_regression, calculate_loss_reg_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_validation_visualization(lambds, loss_tr, loss_te):\n",
    "    \"\"\"visualization the curves of mse_tr and mse_te.\"\"\"\n",
    "    plt.semilogx(lambds, loss_tr, marker=\".\", color='b', label='train error')\n",
    "    plt.semilogx(lambds, loss_te, marker=\".\", color='r', label='test error')\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"neg log-likelihood\")\n",
    "    plt.title(\"cross validation\")\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"cross_validation\")\n",
    "    \n",
    "\n",
    "def cross_validation(y, x, k_indices, k, lambda_, gamma, max_iters):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # get k'th subgroup in test, others in train    \n",
    "    indices_for_test = k_indices[k]\n",
    "    x_test, y_test = x[indices_for_test], y[indices_for_test]\n",
    "    x_training, y_training = np.delete(x, indices_for_test, axis=0), np.delete(y, indices_for_test, axis=0)\n",
    "\n",
    "    # ridge regression\n",
    "    loss_tr, w_opt = reg_logistic_regression(y_training, x_training, lambda_, gamma, max_iters)\n",
    "\n",
    "    # calculate the loss for test data\n",
    "    loss_te = calculate_loss_reg_logistic_regression(y_test, x_test, w_opt, lamda_)\n",
    "    \n",
    "\n",
    "    return loss_tr, loss_te\n",
    "\n",
    "\n",
    "def run_reg_logistic_regression(y, x, gamma, max_iters, k_fold=4,lambdas=np.logspace(-3, 2, 20), \n",
    "                                seed=1, filename=\"bias_var_decom_RLR\"):\n",
    "    \"\"\" Perform Regularized Logistic regression using k-fold cross-validation and plot the training and test error. \n",
    "    By default, the seed is 1 and the whole cross-validation process is done only \n",
    "    once and the result is then plotted.\n",
    "    \"\"\"\n",
    "    if k_fold <= 1:\n",
    "        raise ValueError('The value of k_fold must be larger or equal to 2.')\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "    loss_tr = np.zeros((k_fold, len(lambdas)))\n",
    "    loss_te = np.zeros((k_fold, len(lambdas)))\n",
    "\n",
    "    # K-fold cross-validation:\n",
    "    for k in range(0, k_fold):\n",
    "        for index_lambda, lambda_ in enumerate(lambdas):\n",
    "            loss_tr[k, index_lambda], loss_te[k, index_lambda] = cross_validation(y, x, k_indices, k, lambda_,\n",
    "                                                                                 gamma, max_iters)\n",
    "\n",
    "    # Plot the mean training and test loss for every lambda \n",
    "    cross_validation_visualization(lambdas, np.mean(loss_tr, axis =0), np.mean(loss_te, axis=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_reg_logistic_regression(y, processed_tx, 0.1, 500)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
